---
layout: post
title: "Llama 4 released"
date: 2025-04-05
tags: ["llm", "meta", "llama", "llama4", "vlm"]
last_updated: 2025-04-07
author: "Nils Durner"
categories: [journal]
---

Llama 4 has been released - partially. It's a suite of three LLMs, with the biggest model ("Behemoth") still in training. Notes:
* ~apparently no restrictions on use within the EU~ [see Update below]
* ~trained in fp8 precision~ [see Update below]
* already live on OpenRouter
    * via Together: smallest model "Scout" costlier than Gemini 1.5 Pro on my first tests
    * also available from Groq and Fireworks, much cheaper than Together
* [Hugging Face model collection](https://huggingface.co/collections/meta-llama/llama-4-67f0c30d9fe03840bc9d0164)
* Maxime Labonne points out [license problems](https://x.com/maximelabonne/status/1908602756182745506)

[Update]
The [Acceptable Use Policy](https://www.llama.com/llama4/use-policy/) does place restrictions on EU citizens:
> With respect to any multimodal models included in Llama 4, the rights granted under [Section 1(a) of the Llama 4 Community License Agreement](https://www.llama.com/llama4/license/) are not being granted to you if you are an individual domiciled in, or a company with a principal place of business in, the European Union. This restriction does not apply to end users of a product or service that incorporates any such multimodal models.
([via](https://x.com/TheXeophon/status/1908623432603881698))

[Update 2025-04-06]
While it was trained in fp8, weights are released in bf16:
> The Llama 4 Scout model is released as BF16 weights, but can fit within a single H100 GPU with on-the-fly int4 quantization; the Llama 4 Maverick model is released as both BF16 and FP8 quantized weights. The FP8 quantized weights fit on a single H100 DGX host while still maintaining quality.
([Model card](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct))

Providers Groq, Fireworks and Together are not advertised as bf16 on OpenRouter, but DeepInfra is.

[Update 2025-04-06 #2]
Testing both Scout and Maverick (fp8) on the process visualization practice examples from my [recent article](ai-assisted-process-visualiaztion-collaboration), they mostly fail - and are never cheaper than Gemini 1.5 Pro.

