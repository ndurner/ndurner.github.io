---
layout: post
title: "OpenAI GPT-5 release"
date: 2025-08-07
tags: [llm, openai, gpt4, gpt5, chatgpt]
last_updated: 2025-08-09
author: "Nils Durner"
categories: [journal]
---

## Introduction
OpenAI has released the much anticipated GPT-5 model. [System card](https://openai.com/index/gpt-5-system-card/). [It comes](https://platform.openai.com/docs/models) in four flavors: nano, mini, [chat](https://platform.openai.com/docs/models/gpt-5-chat-latest), and [gpt-5 "proper"](https://platform.openai.com/docs/models/gpt-5). Some of these were beta-tested through the OpenRouter platform under the disguise of "Horizon Alpha" and "Horizon Beta". The [Using GPT-5](https://platform.openai.com/docs/guides/latest-model) document details features and includes a migration guide from previous models.

## Prerelease: Horizon Alpha/Beta
These pre-release models showed two particularities in my testing:
* gender bias like [GPT-4.1](_openai-api-gpt-4.1): When asking to assign names to term as [highlighted in the Stanford AI Index](stanford-ai-index), Horizon Alpha and Beta both showed this bias - which I haven't seen with GPT-4o. GPT-5 with minimal reasoning effort (see below) shows this bias, with medium effort it does the alternation. 
* thinking & deliberating on the solution *within* the comments of source code they produced - leading to a lot of non-helpful clutter in the comments

OpenRouter confirms that both models were [early checkpoints of the GPT-5 family](https://www.linkedin.com/posts/openrouter_excited-to-launch-gpt-5-on-openrouter-let-activity-7359290990014185472-5m7r?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAGX2jIBd6RDsNRYv13Bvu3x4nnCNu96SEw).

## Reasoning switch in the API
As established for other reasoning models, the length of the reasoning process can be [somewhat shortened](reasoning-models-no-think). GPT-5 makes this explicit, by extending the reasoning effort parameter to include "minimal". In addition, the `verbosity` level is now configurable, allowing outputs aside from the reasoning process to be more terse:
> When generating code, medium and high verbosity levels yield longer, more structured code with inline explanations, while low verbosity produces shorter, more concise code with minimal commentary.

(quote from [Using GPT-5](https://platform.openai.com/docs/guides/latest-model)).

To use GPT-5 without any reasoning in the API, the [Introducing GPT-5 for developers](https://openai.com/index/introducing-gpt-5-for-developers/) document recommends:
> The non-reasoning model used in ChatGPT is available as gpt-5-chat-latest.

So the "gpt-5-chat" model in the API seems to be what's called "gpt-5-main" in the System Card? In contrast to the other models in the API, this one is not versioned - from the Model Card: "GPT-5 Chat points to the GPT-5 snapshot currently used in ChatGPT."

## API vs ChatGPT
Some of the things presented on the live stream are not available in the API:
* GPT-5 Pro: the model gpt-5-thinking-pro, as the migration path from o3-pro, is exclusive to ChatGPT Pro: "In ChatGPT, we also provide access
to gpt-5-thinking using a setting that makes use of parallel test time compute; we refer to this as gpt-5-thinking-pro." (quote from the System Card)
* the improved audio input/output

The API gives explicit control over which model to use, however. In ChatGPT, a model router takes control of that, and users may have to signal which route to take ("think hard about this"). Per the System Card, the model router will continue to be trained "on real signals, including when users switch models, preference rates for responses, and measured correctness, improving over time". This means that ChatGPT users will see inconsistent results that change over time.

Image generation in either will continue be provided by [gpt-image-1](gpt4o-image-generation) (which was recently improved by the addition of a "High" input fidelity option).

ChatGPT users continue to be downgraded, depending on the suscription they have bought:
> Once usage limits are reached, a mini version of each model handles
remaining queries.

(quoted from the System Card). Unlimited use of GPT-5 is included both in [ChatGPT Team and ChatGPT Pro](https://help.openai.com/en/articles/11909943-gpt-5-in-chatgpt#:~:text=unlimited%20access%20to%20our%20GPT-5%20models).

## For developers
The announcement live stream included [several demoes of using GPT-5 for coding](https://youtu.be/0Uu_VJeVVfo?t=2464). GPT-5 improves strongly on a number of coding-related benchmarks, including Aider Polyglot. [Windsurf](https://x.com/OpenAIDevs/status/1953554951885713859) and [Cursor include GPT-5 use without additional cost](https://x.com/cursor_ai/status/1953519580627742750) of GPT-5 for a limited time. OpenAI's own [Codex CLI](openai-codex-notes) now uses GPT-5 by default, with [usage covered by a (Plus or Pro) ChatGPT subscription](https://x.com/embirico/status/1953526045573059056). There's a "curated collection of demo applications generated entirely in a single GPT-5 prompt, without writing any code by hand": [GPT-5 coding examples](https://gpt-examples.com): [Github repository](https://github.com/openai/gpt-5-coding-examples).
    * contrary to the linked post on X, corporate paid subscriptions may not be eligible for Codex CLI use, as the login flow [excludes Enterprise, Edu, and Team workspaces](https://help.openai.com/en/articles/11381614-codex-cli-and-sign-in-with-chatgpt#:~:text=Who%20can%20use%20the%20new%20sign-in%20flow). Error message: "No eligible ChatGPT workspaces found.", "chatgpt_account_missing".

## API Pricing
Simon Willison has a [nice comparison table](https://simonwillison.net/2025/Aug/7/gpt-5/#:~:text=Input%20%24%2Fm), noting that GPT-5 is cheaper-per-token than GPT-4o (and 4.1; but costlier than o4-mini, especially on outputs). (As always, output lengths vary in terms of the amount of tokens used as this is not a standard unit of measure). Cost savings through implicit inputs caching are substantial: about 1/10 the regular cost (90% off), i.e., $0.125 vs $1.25 per 1M tokens with GPT-5 "proper".

## Availability
* GPT-5 is [slowly](https://help.openai.com/en/articles/6825453-chatgpt-release-notes#:~:text=GPT-5%20is%20slowly%20rolling%20out) rolling out to ChatGPT (including the free tier). In the Enterprise and Edu subscription plan, it will be available "soon".
* Availability on the API is granted to all Tiers (except "Free"), with full support on the OpenAI Prompts Playground and basic (yet evolving) support through my [OAI Chat](oai_chat-updates).
* It's also rolling out to Microsoft platforms, including Microsoft 365 Copilot, Copilot, GitHub Copilot, and Azure AI Foundry.
* While deprecation of all previous models was announced on the live stream, no actual end-of-life dates have been announced for access via API. In ChatGPT, the model picker may get [cleaned up](https://x.com/OpenAI/status/1953526591629508735) to only include GPT-5 models.
    * Conversations with previous models like GPT-4.5 will be [automatically switched to GPT-5](https://help.openai.com/en/articles/6825453-chatgpt-release-notes#:~:text=ChatGPT%20will%20automatically%20switch%20it%20to%20the%20closest%20GPT-5%20equivalent
).
    * For users on corporate plans (Team, Enterprise, Edu), there is [Legacy Model Access](https://help.openai.com/en/articles/11954883-legacy-model-access-for-team-enterprise-and-edu-users#h_ffaadea924), which will give access to previous models (including o3-pro and GPT-4.5) for a limited transition period. This needs to be enabled by ChatGPT workspace admins.

## Benchmark results
* [Fiction.LiveBench Long Context Benchmark](https://fiction.live/stories/Fiction-liveBench-August-8-2025/oQdzQvKHw8JyXbN87): state-of-the-art performance (along with Grok 4)

## Other notes
* Model fine-tuning with GPT-5 as the base model is not available as of now
* German Writing lags behind GPT-4o? ([via])(https://www.linkedin.com/posts/jphme_gpt-5-worse-than-gpt-4o-first-results-activity-7359440737584783360-u6St?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAGX2jIBd6RDsNRYv13Bvu3x4nnCNu96SEw))
* as Ethan Mollick [predicted](https://www.linkedin.com/posts/emollick_you-are-likely-going-to-see-a-lot-of-very-activity-7359323772924878848-Pf_j?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAGX2jIBd6RDsNRYv13Bvu3x4nnCNu96SEw), reports online are very inconsistent - because of the model router in ChatGPT. The router may assign a request to an unsuitable model, as was likely the case in Charlie Meyer's "[Bs in Blueberry](https://blog.charliemeyer.co/the-gpt-5-launch-was-concerning/)" test. I [explained](https://news.ycombinator.com/item?id=44837178) that I could only reproduce this in the API with the non-thinking gpt-5-chat, and not with any of the reasoning models.
    * Sam Altmann [confirms](https://x.com/sama/status/1953893841381273969) that the router (aka "autoswitch") was "out of commission for a chunk of the day and the result was GPT-5 seemed way dumber."
* alleged System Prompt leaks: [1](https://gist.github.com/maoxiaoke/f6d5b28f9104cd856a2622a084f46fd7), [2](https://github.com/lgboim/gpt-5-system-prompt/blob/main/system_prompt.md). According to these:
    * for image generation, the tool name is actually "image_gen", not "ImageGen"
    * "Code Interpreter" is not mentioned, just `Python` as a tool name. That explains recent issues I had with "Use Code Interpreter to..."
    * the Python sandbox does not have Internet access
* in addition to the Tools like image_gen or the Canvas "canmore", there is the Widget system. Widgets are directly rendered in the chat. The only one established so far is "ecosystem_demo.daw_drums" - otherwise known as [beatbot](https://x.com/sama/status/1953529799219319205)

## Open questions
* What's the time-to-first-token, given that there is no true no-thinking model or mode in the API? Does it suffer?
* How does GPT-5 do on third party benchmarks like the [Vectara Hallucination Benchmark](hallucination-benchmark) ~~or the [Fiction.live Long Context Benchmark](https://fiction.live/stories/Fiction-liveBench-July-25-2025/oQdzQvKHw8JyXbN87)~~?
* How does the monitoring - both automated and human - against chemical & bio-threats, as described in the System Card, align with data privacy requirements?

[Updates 2025-08-08]
* ChatGPT Legacy Model Access
* no fine-tuning
* note on lacking(?) German writing proficiency
* unlimited use also in ChatGPT Team
* clarified Cursor pricing
* added note on "Bs in Blueberry", where gpt-5-chat fails to count letters
* Codex CLI usage may not be included in corporate ChatGPT subscriptions (see above)
* Fiction.live Long Context Benchmark results added, model router failure confirmed

[Updates 2025-08-09]
* reference to alleged System Prompts added, plus "beatbot"