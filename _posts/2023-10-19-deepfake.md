---
layout: post
title: "DeepFake?"
date: 2023-10-19
last_updated: 2023-10-19
description: "Analyzes viral AI 'impersonation attack' video, identifying high frame variance, low frame rate, and comparing to established deepfake detection/creation methods."
tags: [DeepFake, Generative AI, Impersonation]
---

[A video](https://x.com/yokohara_h/status/1714677568023285840?s=46&t=tKoAWd7etyatheAmJYRJvA) is trending on social media that makes some thing of "impersonation attacks". My take: just „clickbait“, and not a real threat:
* inter-frame variance too high, caused by different hallucination artifacts introduced into each individual frame. See screenshots.
* very low-frame rate, obviously. Scaling it up may introduce even more artifacts, especially ones perhaps unnoticeable for humans but very noticeable in Computer Vision.
* If it *were* done properly, it’d basically be the same problem area as deep-fakes, and from what I have heard - as an outsider even!, about the counter-measures, I would expect deployed technology to easily catch this.
* the image generation AI model can not, in fact, generate faces: see the guy that appears in the background. She‘s wearing a mask for a reason. :smiley:
* Playing voice and character models like an instrument is an established content creation technique. For example, the facial expressions and movements of the biggest sculpture at Taiwan Lantern Festival 台灣燈會 this year were in fact played by an actress, captured by a large sensor array and then used to bring the sculpture alive: https://youtu.be/8dtywyJRcX8?si=l4440viJgLMw_mXa in the most realistic way possible. By comparison, this Twitter poster is not even trying. :-)

![Screenshot #1](assets/img/IMG_7513.jpg)
![Screenshot #2](assets/img/IMG_7515.jpg)